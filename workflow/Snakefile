import os
import glob
import numpy as np

# Set default configuration file (can be over-written in snakemake call)
configfile: "config/config.yaml"

if os.path.exists(config["input_bam_folder"]):
    # Extract samples names from BAM files
    input_bam_files = glob.glob(os.path.join(config["input_bam_folder"], "*.bam"))

    if len(input_bam_files) == 0:
        raise ValueError("No BAM files found in '" + config["input_bam_folder"] + "'")
else:
    raise ValueError("Cannot find BAM files as folder '" + config["input_bam_folder"] + "' does not exist")

# Get names per sample from the BAMs, e.g. "b-cell.bam" would use "b-cell"
sample_names = np.array([os.path.split(bam_path)[-1].replace(".bam", "") for bam_path in input_bam_files])

try:
    # Check if barcode split files are already provided per sample
    barcode_preset_folder = str(config["barcode_preset_folder"])
except:
    print("Warning: \"barcode_preset_folder\" was not found in config file")
    barcode_preset_folder = ""

if (len(barcode_preset_folder) > 0) and (barcode_preset_folder.lower() != "none"):
    if not os.path.exists(barcode_preset_folder):
        raise ValueError("Preset barcode folder doesn't exist")

    # See if text files are within the folder
    barcode_preset_files = glob.glob(os.path.join(barcode_preset_folder, "*.txt"))

    if len(barcode_preset_files) == 0:
        raise ValueError("No files found in preset barcode folder '" + barcode_preset_folder + "'")
    
    # Get the sample names from the file names
    barcode_samples = [file.split(os.sep)[-1].removesuffix(".txt").removeprefix("barcode_split_") for file in barcode_preset_files]
    # Test if all files match a BAM files
    missing_barcodes = np.setdiff1d(sample_names, barcode_samples)

    if len(missing_barcodes) > 0:
        raise ValueError("The following samples are missing preset barcode files: " + ", ".join(missing_barcodes) + ".\n" +
                         "These need to be named as barcode_split_sample.txt")

    print("Using preset barcode files for all samples")
    use_preset_barcodes = True
    barcode_folder = barcode_preset_folder

    # Set the minimum number of cells allowed to create a BAM
    min_cells = config["min_cells"]

    try:
        min_cells = max(1, int(min_cells))
    except:
        raise ValueError("min_cells must be an integer >= 1")

    if min_cells > 1:
        print(f"Set to ensure that each pseudobulk has at least {min_cells} cells")

else:
    use_preset_barcodes = False
    barcode_folder = os.path.join(config["result_folder"], config["barcode_split_folder"])

    pseudo_size = config["pseudo_size"]

    try:
        pseudo_size = max(1, int(pseudo_size))
    except:
        raise ValueError("pseudo_size must be an integer >= 1")

    print(f"Set to create pseudobulks with {pseudo_size} cells")

    # Set cell limit to match the pseudobulk size
    min_cells = pseudo_size

# Check if any index files are missing
indexes_exist = np.array([os.path.isfile(os.path.join(config["input_bam_folder"], sample + ".bam.bai")) for sample in sample_names])
use_preset_indexes = True

if not np.all(indexes_exist):
    # Indexes need to be created
    use_preset_indexes = False
    # Check if any made in previous run
    indexes_made = np.array([os.path.isfile(os.path.join(config["result_folder"], config["sorted_bam_folder"], sample + ".bam.bai")) for sample in sample_names])

    if not np.all(indexes_made):
        print("The following sample(s) are missing BAM index files:", ", ".join(sample_names[np.where(~indexes_made)]))

# Set folder with BAMs to create pseudobulks from
if use_preset_indexes:
    # Use original BAMs
    bam_folder = config["input_bam_folder"]
else:
    # Use sorted BAMs
    bam_folder = config["sorted_bam_folder"]

# Set name of peak caller
peak_caller = str(config["peak_caller"]).lower()

# Check if peak caller set
if peak_caller == "none":
    peak_caller = None
    peak_postfix = ""
elif peak_caller == "lanceotron":
    # Peak BED file name depends on which peak caller is run
    peak_postfix = "_L-tron"
else:
    peak_caller = "macs3"
    peak_postfix = "_summits"

def getSplitSampleResults(wildcards):
    # Call the checkpoint to force it to complete before evaluating and get the directory 
    # where a sample's split BAM files are created, e.g. "Results/pseudobulks/b-cell/"
    pseudobulk_folder = checkpoints.sinto.get(**wildcards).output["pseudobulk_folder"]
    # Find the names of the pseudobulks for the sample
    pseudobulk_wildcards = glob_wildcards(os.path.join(pseudobulk_folder, "{pseudobulk}.bam")).pseudobulk
    # Create list of pseudobulk bigWigs or peaks for the sample
    # e.g. ["Results/pseudobulks/b-cell/b-cell_1.bed",
    #       "Results/pseudobulks/b-cell/b-cell_2.bed",
    #       "Results/pseudobulks/b-cell/b-cell_3.bed"]
    if peak_caller is None:
        # Use bigWigs if not using peak calling
        pseudobulk_results = expand(os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}.bw"), pseudobulk = pseudobulk_wildcards, allow_missing = True)
    else:
        # Use peak calls if they should be created
        pseudobulk_results = expand(os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}" + peak_postfix + ".bed"), pseudobulk = pseudobulk_wildcards, allow_missing = True)
    
    return pseudobulk_results

# Define output files to create
rule all:
    input:
        #cell_barcode_files = expand(os.path.join(barcode_folder, "barcode_split_{sample}.txt"), sample = sample_names)
        summary_csv = os.path.join(config["result_folder"], config["summary_folder"], "summary.csv")

# Check to prevent user inputted barcode files being overwritten
if not use_preset_barcodes:
    # Count the number of times each cell barcode occurs in a BAM and save to text file
    rule barcode_occurrence:
        input:
            bam_file = os.path.join(config["result_folder"], bam_folder, "{sample}.bam")
        output:
            barcode_count = os.path.join(config["result_folder"], config["barcode_count_folder"], "barcode_count_{sample}.txt")
        shell:
            """
                echo "Counting barcodes for" {wildcards.sample}
                samtools view {input.bam_file} | cut -f 12- | tr '\t' '\n' | grep CB:Z: | sed 's/CB:Z://' | sort | uniq -c > {output.barcode_count}
            """

    # For each sample, label its cell barcodes with a pseudobulk name
    rule barcode_splitter:
        input:
            barcode_count_file = rules.barcode_occurrence.output.barcode_count
        params:
            sample_name = "{sample}"
        output:
            cell_barcode_file = os.path.join(barcode_folder, "barcode_split_{sample}.txt")
        script:
            "scripts/BarcodeSplitter.py"

if not use_preset_indexes:
    rule sort_BAM:
        input:
            unsorted_bam_file = os.path.join(config["result_folder"], config["input_bam_folder"], "{sample}.bam")
        output:
            sorted_bam_file = os.path.join(config["result_folder"], config["sorted_bam_folder"], "{sample}.bam")
        shell:
            """
            samtools sort -o {output.sorted_bam_file} {input.unsorted_bam_file}
            """

    # Create index for each input BAM
    rule index_BAM:
        input:
            bam_file = os.path.join(config["result_folder"], config["sorted_bam_folder"], "{sample}.bam")
        output:
            bai_file = os.path.join(config["result_folder"], config["sorted_bam_folder"], "{sample}.bam.bai")
        shell:
            """
            samtools index {input.bam_file}
            """

# Split each BAM file (which has enough cells) to generate pseudobulks
# e.g. "b-cell.bam" into "b-cell_1.bam", "b-cell_2.bam", "b-cell_3.bam"
checkpoint sinto:
    input:
        bam_file = os.path.join(config["result_folder"], bam_folder, "{sample}.bam"),
        bai_file = os.path.join(config["result_folder"], bam_folder, "{sample}.bam.bai"),
        cell_barcode_file = os.path.join(barcode_folder, "barcode_split_{sample}.txt")
    params:
        barcode_tag = config["barcode_tag"],
        min_cells = min_cells
    output:
        pseudobulk_folder = directory(os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}"))
    threads: config["subprocess_threads"]
    shell:
        """
        echo "Splitting BAMs into pseudobulks for" {wildcards.sample}
        if [[ $(wc -l < {input.cell_barcode_file}) -ge {params.min_cells} ]] && [[ $(head -n 1 {input.cell_barcode_file}) != Not* ]]
        then
            echo "Running sinto on" {wildcards.sample}
            sinto filterbarcodes -b {input.bam_file} -c {input.cell_barcode_file} --barcodetag "CB" --nproc {threads} --outdir {output.pseudobulk_folder}
        else
            echo "Skipping" {wildcards.sample} "as there are not enough cells to create pseudobulks"
            mkdir {output.pseudobulk_folder}
        fi
        """

# Generate index for each pseudobulk BAM
rule create_index:
    input:
        bam_file = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}.bam")
    output:
        bam_index = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}.bam.bai")
    shell:
        """
        echo "Creating index for" {wildcards.sample}
        samtools index {input.bam_file}
        """

# Generate bigWig per pseudobulk BAM
rule create_bigwig:
    input:
        bam_file = rules.create_index.input["bam_file"],
        bam_index = rules.create_index.output["bam_index"]
    params:
        norm_method = config["norm_method"],
        bin_size = config["bin_size"]
    output:
        bigwig = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}.bw")
    threads: config["subprocess_threads"]
    shell:
        """
        bamCoverage -b {input.bam_file} -o {output.bigwig} -bs {params.bin_size} --normalizeUsing {params.norm_method} --numberOfProcessors {threads}
        """

rule call_peaks:
    input:
        bam_file = rules.create_bigwig.input.bam_file,
        bam_index = rules.create_bigwig.input.bam_index,
        bigwig = rules.create_bigwig.output.bigwig
    params:
        peak_caller = peak_caller,
        folder = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}")
    output:
        peaks = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}" + peak_postfix + ".bed"),
        r_model = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}_model.r") if peak_caller == "macs3" else [],
        narrow_peaks = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}_peaks.narrowPeak") if peak_caller == "macs3" else [],
        xls_peaks = os.path.join(config["result_folder"], config["pseudobulk_folder"], "{sample}", "{pseudobulk}_peaks.xls") if peak_caller == "macs3" else []
    shell:
        """
            if ["{params.peak_caller}" == "lanceotron"]
            then
                lanceotron callPeaks {input.bigwig} -f {params.folder}
            else
                macs3 callpeak --treatment {input.bam_file} --outdir {params.folder} --name {wildcards.pseudobulk}
            fi
        """

# Create temporary file per sample to ensure that indexes and bigwigs are made
rule temp_aggregate:
    input:
        # Force creation of bigWigs and/or peaks for each pseudobulk by using them as a fake dependency
        sample_results = getSplitSampleResults,
        # Input cell barcode file to fill in the sample wildcard in case sample_results is empty
        cell_barcode_file = os.path.join(barcode_folder, "barcode_split_{sample}.txt")
    output:
        # Temporary file to create containing names of all pseudobulks for the sample
        finished_file = temp(os.path.join(config["result_folder"], config["temp_folder"], "finished_processing_{sample}.txt"))
    shell:
        """
        printf "%s\n" {input.sample_results} > {output.finished_file}
        """

# Ensure creation of desired outputs, create summary file and remove temporary files
rule clean_up:
    input:
        # Input the temporary files to force their creation and automatically remove them after this rule completes
        finished_files = expand(os.path.join(config["result_folder"], config["temp_folder"], "finished_processing_{sample}.txt"), sample = sample_names),
    params:
        barcode_folder = barcode_folder,
        file_prefix = "finished_processing_",
        use_preset_barcodes = use_preset_barcodes,
        min_cells = min_cells,
    output:
        # Create a CSV summarising the pseudobulks created for each sample
        summary_csv = os.path.join(config["result_folder"], config["summary_folder"], "summary.csv")
    script:
        "scripts/CleanUp.py"
